{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dfe81d0-2970-4777-b3d0-fc01b01aa032",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ea4e03-3097-43a2-8803-4dc7f39cdd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-1.99.9-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /srv/conda/lib/python3.11/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /srv/conda/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /srv/conda/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /srv/conda/lib/python3.11/site-packages (from openai) (2.10.5)\n",
      "Requirement already satisfied: sniffio in /srv/conda/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /srv/conda/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /srv/conda/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /srv/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /srv/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /srv/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /srv/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /srv/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /srv/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Using cached openai-1.99.9-py3-none-any.whl (786 kB)\n",
      "Using cached jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Installing collected packages: jiter, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [openai]2m1/2\u001b[0m [openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed jiter-0.10.0 openai-1.99.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from IPython.display import YouTubeVideo, HTML, display\n",
    "from ipywidgets import interact, widgets\n",
    "%matplotlib inline\n",
    "%pip install openai # You may see an Error pop up, that's fine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6252b7cc-a3b7-4253-9f28-b64968bf38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "When writing code that will go to production (e.g. be seen by other people), \n",
    "you'll usually set your API key as an environment variable via your terminal.\n",
    "\"\"\"\n",
    "# Find the API key we've given you in EdStem\n",
    "API_KEY = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da656740-3e91-46f7-ad30-def0159a8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda9bfd8-6284-4b21-9cc8-97bb8aadf2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>whoTarget</th> <th>intentYN</th> <th>sexYN</th> <th>sexReason</th> <th>offensiveYN</th> <th>annotatorGender</th> <th>annotatorMinority</th> <th>sexPhrase</th> <th>speakerMinorityYN</th> <th>WorkerId</th> <th>HITId</th> <th>annotatorPolitics</th> <th>annotatorRace</th> <th>annotatorAge</th> <th>post</th> <th>targetMinority</th> <th>targetCategory</th> <th>targetStereotype</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>nan      </td> <td>0.66    </td> <td>0.5  </td> <td>oral sex?      </td> <td>nan        </td> <td>woman          </td> <td>nan              </td> <td>eat the cookies  </td> <td>nan              </td> <td>-8935932304856669427</td> <td>3Z33IC0JC0GO2QZ7DPV62JGZ3EZV9N</td> <td>liberal          </td> <td>white        </td> <td>45          </td> <td>Why do black people call black women oreos? Cause they e ...</td> <td>nan                               </td> <td>nan           </td> <td>nan                      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>nan      </td> <td>0       </td> <td>0    </td> <td>nan            </td> <td>0          </td> <td>man            </td> <td>nan              </td> <td>nan              </td> <td>nan              </td> <td>1781840716988750702 </td> <td>3V7ICJJAZAA8W6VPRD8FKZBCG81B4R</td> <td>liberal          </td> <td>white        </td> <td>30          </td> <td>BUT I SOON REALIZED THAT EFFICIENCY AND QUALITY NEED NOT ...</td> <td>nan                               </td> <td>nan           </td> <td>nan                      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0        </td> <td>0.66    </td> <td>0    </td> <td>nan            </td> <td>1          </td> <td>man            </td> <td>nan              </td> <td>nan              </td> <td>nan              </td> <td>-2877140746380073212</td> <td>3S4TINXCC0HC0Z57AXNOYXHHXZ4BO4</td> <td>cons             </td> <td>white        </td> <td>42          </td> <td>that 400bil in savings means less labor cost. less peopl ...</td> <td>nan                               </td> <td>nan           </td> <td>nan                      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1        </td> <td>1       </td> <td>0    </td> <td>nan            </td> <td>1          </td> <td>woman          </td> <td>nan              </td> <td>nan              </td> <td>0                </td> <td>7912096326098817047 </td> <td>31MBOZ6PAOLN4JUGB53RH0J5IXUCLO</td> <td>liberal          </td> <td>white        </td> <td>32          </td> <td>A child climbs up an apple tree with a rope. When it lat ...</td> <td>folks with mental illness/disorder</td> <td>disabled      </td> <td>nan                      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1        </td> <td>1       </td> <td>0    </td> <td>nan            </td> <td>1          </td> <td>woman          </td> <td>none             </td> <td>nan              </td> <td>0                </td> <td>-450836770736143243 </td> <td>338GLSUI435HB89GMGQT1SI3AIWSFQ</td> <td>mod-liberal      </td> <td>white        </td> <td>55          </td> <td>This gay kill a young bulgarian man to protect some crim ...</td> <td>black folks                       </td> <td>race          </td> <td>racist against skin color</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1        </td> <td>1       </td> <td>1    </td> <td>ejaculation    </td> <td>1          </td> <td>man            </td> <td>nan              </td> <td>comes on his face</td> <td>0                </td> <td>-2877140746380073212</td> <td>3UUSLRKAULXYUQBS77XSI1JM8JV7DG</td> <td>cons             </td> <td>white        </td> <td>42          </td> <td>What’s the difference between a priest and acne? Acne wa ...</td> <td>christian folks                   </td> <td>culture       </td> <td>all are child molesters  </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>nan      </td> <td>0       </td> <td>0    </td> <td>nan            </td> <td>0          </td> <td>woman          </td> <td>nan              </td> <td>nan              </td> <td>nan              </td> <td>-5471608738051449110</td> <td>3MZ3TAMYTLHPKKBT8ZW9EFQZ3C8RI2</td> <td>other            </td> <td>white        </td> <td>35          </td> <td>tomorrow, 3 fucking PM EST yall are paying for my fallen ...</td> <td>nan                               </td> <td>nan           </td> <td>nan                      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>nan      </td> <td>0       </td> <td>0    </td> <td>nan            </td> <td>0          </td> <td>woman          </td> <td>nan              </td> <td>nan              </td> <td>nan              </td> <td>955703508749055793  </td> <td>3566S7OX5DD42VVGREDXHZIDMVZ71I</td> <td>liberal          </td> <td>asian        </td> <td>23          </td> <td>TIL that a bunch of Retards think Men's Right's is actua ...</td> <td>nan                               </td> <td>nan           </td> <td>nan                      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0        </td> <td>1       </td> <td>0    </td> <td>nan            </td> <td>1          </td> <td>woman          </td> <td>nan              </td> <td>nan              </td> <td>nan              </td> <td>1993680211374950203 </td> <td>3XUSYT70ITVKCFB8M8CJ3M9Z0130DF</td> <td>mod-liberal      </td> <td>white        </td> <td>47          </td> <td>What was Stephen Hawking’s last meal? His shoulder          </td> <td>nan                               </td> <td>nan           </td> <td>nan                      </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1        </td> <td>0.66    </td> <td>1    </td> <td>referencing sex</td> <td>1          </td> <td>woman          </td> <td>none             </td> <td>I fucked her     </td> <td>0                </td> <td>-3114316428557054065</td> <td>37PGLWGSJT03XGYYIFNCD34L64ZIKN</td> <td>mod-cons         </td> <td>white        </td> <td>33          </td> <td>Never met the bitch but I fucked her like I missed her      </td> <td>women                             </td> <td>gender        </td> <td>women are bitches        </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (990 rows omitted)</p>"
      ],
      "text/plain": [
       "whoTarget | intentYN | sexYN | sexReason       | offensiveYN | annotatorGender | annotatorMinority | sexPhrase         | speakerMinorityYN | WorkerId             | HITId                          | annotatorPolitics | annotatorRace | annotatorAge | post                                                         | targetMinority                     | targetCategory | targetStereotype\n",
       "nan       | 0.66     | 0.5   | oral sex?       | nan         | woman           | nan               | eat the cookies   | nan               | -8935932304856669427 | 3Z33IC0JC0GO2QZ7DPV62JGZ3EZV9N | liberal           | white         | 45           | Why do black people call black women oreos? Cause they e ... | nan                                | nan            | nan\n",
       "nan       | 0        | 0     | nan             | 0           | man             | nan               | nan               | nan               | 1781840716988750702  | 3V7ICJJAZAA8W6VPRD8FKZBCG81B4R | liberal           | white         | 30           | BUT I SOON REALIZED THAT EFFICIENCY AND QUALITY NEED NOT ... | nan                                | nan            | nan\n",
       "0         | 0.66     | 0     | nan             | 1           | man             | nan               | nan               | nan               | -2877140746380073212 | 3S4TINXCC0HC0Z57AXNOYXHHXZ4BO4 | cons              | white         | 42           | that 400bil in savings means less labor cost. less peopl ... | nan                                | nan            | nan\n",
       "1         | 1        | 0     | nan             | 1           | woman           | nan               | nan               | 0                 | 7912096326098817047  | 31MBOZ6PAOLN4JUGB53RH0J5IXUCLO | liberal           | white         | 32           | A child climbs up an apple tree with a rope. When it lat ... | folks with mental illness/disorder | disabled       | nan\n",
       "1         | 1        | 0     | nan             | 1           | woman           | none              | nan               | 0                 | -450836770736143243  | 338GLSUI435HB89GMGQT1SI3AIWSFQ | mod-liberal       | white         | 55           | This gay kill a young bulgarian man to protect some crim ... | black folks                        | race           | racist against skin color\n",
       "1         | 1        | 1     | ejaculation     | 1           | man             | nan               | comes on his face | 0                 | -2877140746380073212 | 3UUSLRKAULXYUQBS77XSI1JM8JV7DG | cons              | white         | 42           | What’s the difference between a priest and acne? Acne wa ... | christian folks                    | culture        | all are child molesters\n",
       "nan       | 0        | 0     | nan             | 0           | woman           | nan               | nan               | nan               | -5471608738051449110 | 3MZ3TAMYTLHPKKBT8ZW9EFQZ3C8RI2 | other             | white         | 35           | tomorrow, 3 fucking PM EST yall are paying for my fallen ... | nan                                | nan            | nan\n",
       "nan       | 0        | 0     | nan             | 0           | woman           | nan               | nan               | nan               | 955703508749055793   | 3566S7OX5DD42VVGREDXHZIDMVZ71I | liberal           | asian         | 23           | TIL that a bunch of Retards think Men's Right's is actua ... | nan                                | nan            | nan\n",
       "0         | 1        | 0     | nan             | 1           | woman           | nan               | nan               | nan               | 1993680211374950203  | 3XUSYT70ITVKCFB8M8CJ3M9Z0130DF | mod-liberal       | white         | 47           | What was Stephen Hawking’s last meal? His shoulder           | nan                                | nan            | nan\n",
       "1         | 0.66     | 1     | referencing sex | 1           | woman           | none              | I fucked her      | 0                 | -3114316428557054065 | 37PGLWGSJT03XGYYIFNCD34L64ZIKN | mod-cons          | white         | 33           | Never met the bitch but I fucked her like I missed her       | women                              | gender         | women are bitches\n",
       "... (990 rows omitted)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Table.read_table(\"SBFv2.trn.csv\")\n",
    "np.random.seed(50)\n",
    "theData = dataset.sample(k=1000, with_replacement = False)\n",
    "theData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9fab5-0ddb-46eb-8e62-3df03eadbf1e",
   "metadata": {},
   "source": [
    "The social bias interference corpus is a model created to determine how and why biased and offensive text is deemed bias. The dataset was created by taking sampled posts from primarily bias rich sources such as Twitter and Reddit, which have indivduals saying some of the most biased and hateful speech on the internet. Furthermore, they searched within websites containing offensive languages. By choosing to draw data from these targeted sources, they were able to ensure enough examples of both hidden and obvious signs of bias to support inference tasks for the LLM. Each post was annotated using the Social Bias Frames schema, which is something that takes the categorical judgements, sich as offensiveness, and free-text descriptions of what the implied statements was trying to say to the targeted groups. These labels were given by Amazon Mechanical Turk workers, with at least three annotators per post and demographic information such as gender, race, and political leaning. While the social bias interference corpus offers insights into bias, its construction also introduces potential limitations. There is a strong focus on bias-heavy sources, meaning the dataset contains an unproportionally large number of offensive statements, which is not comparable to everyday language. This language reflects the culture on things such as Reddit and Twitter. Furthermore, whatever is being analyzed is largely subjective and shaped by the past of the person who labeled it. What this means is that certain biases may be overlooked or differently interpreted in other contexts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8149d9f4-e1ce-4308-9fdf-b241f361cc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 689),\n",
       " ('a', 598),\n",
       " ('i', 481),\n",
       " ('to', 451),\n",
       " ('and', 389),\n",
       " ('of', 292),\n",
       " ('you', 288),\n",
       " ('in', 239),\n",
       " ('is', 236),\n",
       " ('that', 184),\n",
       " ('my', 177),\n",
       " ('it', 166),\n",
       " ('for', 163),\n",
       " ('.', 143),\n",
       " ('on', 130),\n",
       " ('with', 126),\n",
       " ('they', 125),\n",
       " ('have', 122),\n",
       " ('are', 121),\n",
       " ('do', 120)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = {} \n",
    "\n",
    "for post in theData.column(\"post\"):\n",
    "    words = post.lower().split()  # lowercase + split on whitespace\n",
    "    for word in words:\n",
    "        if word not in word_counts:\n",
    "            word_counts[word] = 1\n",
    "        else:\n",
    "            word_counts[word]+=1\n",
    "\n",
    "# This sorts our dictionary based off the corresponding frequency, and turns it into a list.\n",
    "word_counts = sorted(word_counts.items(), key=lambda item: item[1], reverse = True)\n",
    "word_counts[:20]  # Display the top 20 most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbb47ce8-b6d8-4fd4-9e34-c68f6f8055ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TF-IDF scores: 100%|██████████| 4920/4920 [00:25<00:00, 192.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('fucking', 0.00093337359284506496),\n",
       " ('co', 0.00055240477943891602),\n",
       " ('https', 0.00053335633876860856),\n",
       " ('rt', 0.00053335633876860856),\n",
       " ('128514', 0.00051430789809830122),\n",
       " ('bitches', 0.00047621101675768626),\n",
       " ('ass', 0.00047621101675768626),\n",
       " ('fuck', 0.00045716257608737881),\n",
       " ('bitch', 0.00045716257608737881),\n",
       " ('shit', 0.00036192037273584154),\n",
       " ('u', 0.00034287193206553409),\n",
       " ('child', 0.00032382349139522669),\n",
       " ('hoes', 0.00030477505072491919),\n",
       " ('sex', 0.00030477505072491919),\n",
       " ('128557', 0.00030477505072491919),\n",
       " ('niggas', 0.00028572661005461179),\n",
       " ('jews', 0.00028572661005461179),\n",
       " ('releasethememo', 0.00028572661005461179),\n",
       " ('fucked', 0.00026667816938430428),\n",
       " ('kids', 0.00026667816938430428)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string \n",
    "def count(w, r):\n",
    "    total = 0\n",
    "    splittedR = r.split()\n",
    "    for i in splittedR:\n",
    "        if i == w:\n",
    "            total+=1\n",
    "    return total\n",
    "\n",
    "def total_words(r):\n",
    "    \"\"\"\n",
    "    Returns the number of words in the Post r, separated by whitespace.\n",
    "\n",
    "    >>> post = \"hello there friend!\"\n",
    "    >>> total_words(post)\n",
    "    3\n",
    "    \"\"\"\n",
    "    splittedR = r.split()\n",
    "    return(len(splittedR))\n",
    "\n",
    "def df(w, lst):\n",
    "    count = 0\n",
    "    for doc in lst:\n",
    "        docSplit = doc.split()\n",
    "        for word in docSplit:\n",
    "            if word == w:\n",
    "                count+=1\n",
    "                break\n",
    "    return count\n",
    "\n",
    "def tf_idf(w, r, lst):\n",
    "    \"\"\"\n",
    "    Compute the tf_idf score for word w within reddit post r.\n",
    "    To compute the inverse document frequency, use lst, the set of documents.\n",
    "    \"\"\"\n",
    "    # Term Frequency (TF)\n",
    "    tf = count(w, r) / total_words(r)\n",
    "\n",
    "    # Inverse Document Frequency (IDF)\n",
    "    N = len(lst)\n",
    "    df_w = df(w, lst)\n",
    "    idf = np.log(N /(1 + df_w))\n",
    "    return tf * idf\n",
    "\n",
    "\n",
    "\n",
    "# Convert txt files into a string\n",
    "text_data = \" \".join(theData.column(\"post\")).lower().replace(\"&amp;\", \" \")\n",
    "for p in string.punctuation:\n",
    "    text_data = text_data.replace(p, \" \")\n",
    "array_text_data = text_data.split()\n",
    "\n",
    "# Save to a text file\n",
    "    \n",
    "\n",
    "with open(\"beemovie.txt\", \"r\") as file:\n",
    "    bee_text = file.read()\n",
    "for p in string.punctuation:\n",
    "    bee_text = bee_text.replace(p, \" \")\n",
    "\n",
    "with open(\"constitution.txt\", \"r\") as file:\n",
    "    constitution_text = file.read()\n",
    "for p in string.punctuation:\n",
    "    constitution_text = constitution_text.replace(p, \" \")\n",
    "\n",
    "theData_bee_constitution = [text_data.lower(), bee_text.lower(), constitution_text.lower()]\n",
    "\n",
    "\n",
    "word_highest_tf_idf = {}\n",
    "word_scores = {}\n",
    "\n",
    "# Iterate through each unique word in the pizza dataset\n",
    "for word in tqdm(set(array_text_data), desc=\"Processing TF-IDF scores: \"):\n",
    "    score = tf_idf(word, text_data, theData_bee_constitution) # TF-IDF for that word, in the entire Reddit dataset, using the 3-document corpus\n",
    "    word_scores[word] = score # Store the TF-IDF for that word\n",
    "\n",
    "    max_score = max(word_scores.values())\n",
    "\n",
    "    #This does not work!\n",
    "    # for word, score in word_scores.items():\n",
    "    #     if score == max_score:\n",
    "    #         if word not in word_highest_tf_idf:\n",
    "    #             word_highest_tf_idf[word] = 1\n",
    "    #         else:\n",
    "    #             word_highest_tf_idf[word] += 1\n",
    "\n",
    "word_highest_tf_idf = sorted(word_scores.items(), key=lambda item: item[1], reverse=True)[:20]\n",
    "word_highest_tf_idf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e096a3b-f5aa-491e-9866-a115849d4bb1",
   "metadata": {},
   "source": [
    "The TF-IDF results tell us that the words that are frequent in our hatespeech dataset but rare in *The Bee Movie* and the US Constitution, showing us the language and topics that are unique to our dataset. The fact that words such as \"fuck\" and \"ass\" are ranked so high reflects how informal and agressive the tone used by people on online discussions can be. The high ranking of various derogatory terms indicates that many discussions revolve around targeted insults, slurs, and sexually explicit language. The less frequent terms (\"releasethememo\", emoji ASCIs) appear in this ranking because they are super rare when comparing across the corpus. This gives them high TF-IDF scores despite lower overall use throughout the dataset. Overall, we feel as though these results show us that sites such as Reddit, Twitter, and hate-focused forums are very casual in nature, modern in language, and house occasionally very hostile conversations that are not very similar to the neutral and formal text found in the other two documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290ce038-d9d8-443e-99df-270c0067fd1e",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f4cd225-e9b7-48ae-a6fd-8ce3cb2e7493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th></th> <th>Maybe</th> <th>No</th> <th>Yes</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Maybe</td> <td>1    </td> <td>3   </td> <td>5   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>No   </td> <td>3    </td> <td>18  </td> <td>1   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Yes  </td> <td>1    </td> <td>1   </td> <td>17  </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "to_label = theData.sample(50, with_replacement = False).select(\"post\")\n",
    "to_label.to_csv('labels.csv')\n",
    "bashar = Table.read_table(\"labels_bashar.csv\")\n",
    "nishanth = Table.read_table(\"labels_nishanth.csv\")\n",
    "to_label = to_label.with_column(\"Bashar\", bashar.column(\"Offensive?\")).with_column(\"Nishanth\", nishanth.column(\"Offensive?\"))\n",
    "pivoted = to_label.pivot(\"Bashar\", \"Nishanth\").relabel(\"Nishanth\",\"\")\n",
    "pivoted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc9b5a8d-2c29-45cc-80c2-e8ea968b2259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54367666232073009"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cohen_kappa_yes_no_maybe(mm, nm, ym,\n",
    "                             mn, nn, yn,\n",
    "                             my, ny, yy):\n",
    "\n",
    "    total = yy + yn + ym + ny + nn + nm + my + mn + mm\n",
    "\n",
    "    # observed agreement\n",
    "    po = (yy + nn + mm) / total\n",
    "\n",
    "    # row marginals first rater\n",
    "    row_yes   = (yy + yn + ym) / total\n",
    "    row_no    = (ny + nn + nm) / total\n",
    "    row_maybe = (my + mn + mm) / total\n",
    "\n",
    "    # column marginals second rater\n",
    "    col_yes   = (yy + ny + my) / total\n",
    "    col_no    = (yn + nn + mn) / total\n",
    "    col_maybe = (ym + nm + mm) / total\n",
    "\n",
    "    # expected agreement\n",
    "    pe = (row_yes * col_yes) + (row_no * col_no) + (row_maybe * col_maybe)\n",
    "\n",
    "    kappa = (po - pe) / (1 - pe)\n",
    "    return kappa\n",
    "\n",
    "kappa = cohen_kappa_yes_no_maybe(pivoted[1][0], pivoted[1][1], pivoted[1][2],\n",
    "                              pivoted[2][0], pivoted[2][1], pivoted[2][2],\n",
    "                              pivoted[3][0], pivoted[3][1], pivoted[3][2])\n",
    "\n",
    "kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8843a2e6-324b-471a-861b-6b5696efcf6d",
   "metadata": {},
   "source": [
    "**Reflection**:\n",
    "\n",
    "Our experience on hand coding was not at all bad, and it was pretty simple to label our data even with options for our one variable. We thought it would be tedious and challenging because there would be so much data to label in an subjective manner, but in the end, the screening/labeling process, at least for only one variable, did not take long at all. We did disagree on quite a few labels, particularly when one person labeled \"maybe\" and the other labeled either \"yes\" or \"no\", but we agreed on a lot more. A Kappa of ~0.54 indicates that we agreed more than would be expected by chance. 36 of our data points were the same, with agreement on 17 yes's, 18 no's, and 1 maybe. We feel as though these numbers are not out of the ordinary. One difficulty was implementing the cohen's kappa function for a 3x3 confusion matrix, which was a bit tedious to hard code. One insighted we gained is the neccesity to ensure all annotators perform their labeling in a standardized manner; this avoids the need for data cleaning/reformating at later stage when the data is ready to be aggregated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965b4bab-c5d4-4544-8be1-04327d2e6856",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "817feb55-cd2a-4592-9fd1-b99328eb03b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33fdde1f-1322-41de-ae75-38ef36a963b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "promptv1 = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are an annotator for a social-bias classification task. \"\n",
    "            \"Label a post yes, no, or maybe for maybe based on offensiveness.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"developer\",\n",
    "        \"content\": (\n",
    "            \"Instructions:\\n\"\n",
    "            \"- Output exactly one of: 'Yes', 'No', 'Maybe'.\\n\"\n",
    "            \"- Do not include explanations.\\n\"\n",
    "            \"- Profanity alone does not guarantee '1'. Consider whether the language targets a person or group.\"\n",
    "            \"\\n\\nExample:\"\n",
    "            \"\\nInput: I love this movie\"\n",
    "            \"\\nOptions: Yes / No / Maybe\"\n",
    "            \"\\nOutput: No\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\" \n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6752004-c007-4aee-8aca-ee09e013d5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "promptv2 = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                        \"You are an expert annotator for the Social Bias Frames dataset.\"\n",
    "                        \"Your task to assign a given social media post entry with one of the following labels based on whether\"\n",
    "                        \"the post is offensive or not: '1.0' for yes, '0.0' for no, '0.5' for maybe based on the dataset's definition of offensiveness:\"\n",
    "                        \"content that targets a group or individual with bias, prejudice, or harmful stereotypes. \"\n",
    "                        \"Profanity alone is not necessarily offensive if not directed at a group or individual. \"\n",
    "                        \"Sarcasm, in-group usage, and self-referential slurs should be judged in context. \"\n",
    "                        \"Even if you are uncertain, you must pick exactly one label.\"\n",
    "                    )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": (\n",
    "                        \"Instructions:\"\n",
    "                        \"\\n-Output solely the appropriate label '1.0', '0.0', or '0.5'.\"\n",
    "                        \"\\n-Do not add explanations or any other text.\"\n",
    "                        \"\\n-Treat group-targeted bias as offensive, even if it is phrased as a joke.\"\n",
    "                        \"\\n-Profanity alone is not enough to be considered offensive; consider the intention and target of the post\"\n",
    "                        \"\\n-Do not make up information; do not output hallucinated information.\"\n",
    "                        \"\\n\\nExamples:\"\n",
    "                        \"\\nInput: What shines the most in a black person? The handcuffs\"\n",
    "                        \"\\nOption 1. 1.0\"\n",
    "                        \"\\nOption 2. 0.0\"\n",
    "                        \"\\nOption 3. 0.5\"\n",
    "                        \"\\nOutput: 1\"\n",
    "                        \"\\n\\nInput: I love Christopher Nolan films!\"\n",
    "                        \"\\nOption 1. 1.0\"\n",
    "                        \"\\nOption 2. 0.0\"\n",
    "                        \"\\nOption 3. 0.5\"\n",
    "                        \"\\nOutput: 0\"\n",
    "                        \"\\nInput: Oh great, another woman driver holding up traffic\"\n",
    "                        \"\\nOption 1. 1.0\"\n",
    "                        \"\\nOption 2. 0.0\"\n",
    "                        \"\\nOption 3. 0.5\"\n",
    "                        \"\\nOutput: 1.0\"\n",
    "            )\n",
    "        },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\n",
    "    }\n",
    "    ]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b299c93-f9b0-48b1-9caa-297c2b353479",
   "metadata": {},
   "outputs": [],
   "source": [
    "promptv3 = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                        \"You are an expert annotator for the Social Bias Frames dataset.\"\n",
    "                        \"Your task to assign a given social media post entry with one of the following labels based on whether\"\n",
    "                        \"the post is offensive or not: '1.0' for yes, '0.0' for no, '0.5' for maybe based on the dataset's definition of offensiveness:\"\n",
    "                        \"content that targets a group or individual with bias, prejudice, or harmful stereotypes. \"\n",
    "                        \"Profanity alone is not necessarily offensive if not directed at a group or individual. \"\n",
    "                        \"Sarcasm, in-group usage, and self-referential slurs should be judged in context. \"\n",
    "                        \"Even if you are uncertain, you must pick exactly one label.\"\n",
    "                        \"If the target or intent is truely unclear and cannot be inferred but the content could be interpreted as offensive, output '0.5'.\"\n",
    "\n",
    "                    )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": (\n",
    "                        \"Instructions:\"\n",
    "                        \"\\n-Output solely the appropriate label '1.0', '0.0', or '0.5'.\"\n",
    "                        \"\\n-Do not add explanations or any other text.\"\n",
    "                        \"\\n-Treat group-targeted bias as offensive, even if it is phrased as a joke.\"\n",
    "                        \"\\n-Profanity alone is not enough to be considered offensive; consider the intention and target of the post\"\n",
    "                        \"\\n-Do not make up information; do not output hallucinated information.\"\n",
    "                        \"\\n\\nExamples:\"\n",
    "                        \"\\nInput: What shines the most in a black person? The handcuffs\"\n",
    "                        \"\\nOption 1. 1.0\"\n",
    "                        \"\\nOption 2. 0.0\"\n",
    "                        \"\\nOption 3. 0.5\"\n",
    "                        \"\\nOutput: 1\"\n",
    "                        \"\\n\\nInput: I love Christopher Nolan films!\"\n",
    "                        \"\\nOption 1. 1.0\"\n",
    "                        \"\\nOption 2. 0.0\"\n",
    "                        \"\\nOption 3. 0.5\"\n",
    "                        \"\\nOutput: 0\"\n",
    "                        \"\\nInput: Oh great, another woman driver holding up traffic\"\n",
    "                        \"\\nOption 1. 1.0\"\n",
    "                        \"\\nOption 2. 0.0\"\n",
    "                        \"\\nOption 3. 0.5\"\n",
    "                        \"\\nOutput: 1.0\"\n",
    "                        \"\\nInput: Woah, are you two sisters? You look so much alike!\"\n",
    "                        \"\\nOption 1. 1.0\"\n",
    "                        \"\\nOption 2. 0.0\"\n",
    "                        \"\\nOption 3. 0.5\"\n",
    "                        \"\\nOutput: 0.5\"\n",
    "            )\n",
    "        },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\n",
    "    }\n",
    "    ]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1860b090-c78b-43d6-8971-c93fb47df18f",
   "metadata": {},
   "source": [
    "        V1 was our baseline prompt to see what the model would output without many instructions. The most prominent problem with v1 of our prompt was that is lacked context about the dataset. It had no definition of what is considered \"offensive\", leaving the model to apply its own arbitrary criteria. Another major failure of this prompt was not properly formatting the llm outputs; the gold labels in the dataset are represented by float values (1.0, 0.0, and 0.5), while this prompt formatted the llm outputs as \"yes\", \"no\", and \"maybe\". This, in combination with a lack of further constraints, resulted in explanatory outputs like \"Yes because...\" or quantifiers such as \"likely yes\". This made resulted in unstandardized outputs that did not map to the gold labels, making them difficult to analyze using an f1 score.\n",
    "       In v2, we followed the prompting guidelines contained in Ziem's paper closely, clearly defining the constraints for determining offensiveness; this included context regarding concepts listed in the original paper such as sarcasm and self-referential slurs. In this version of the prompt, we made it explicitly clear that the output should be strictly one of the three possible labels. This removed the case in which the model outputted something other than expected. We also included three few-shot examples in this prompt, two with offensive posts and one without, giving the model more clear reference for how to handle various cases. We implemented stricter guidelines on output, properly formatting them as strings of floats, and what is considered \"offensive\" in the context of the data. One major improvement was making it clear that the use of profanity does not immediately indicate whether a post is offensive or not. This was a large problem in v1, as the model often labeled neutral posts as \"1.0\" purely because of the fact that they used profane language. Despite including instructions to not provide explanation, the model's output was still too verbose in a few cases. It also underused the 0.5 or \"maybe\" label, indicating that we needed more clear-cut boundaries on what to do in the case of uncertainty.\n",
    "        After calculating the performance of prompt v2, we noticed that the model never correctly labeled 0.5 cases, and barely used the label in general. In v3, we focused on improving the model’s ability to label dynamically; that is, straying away from binary outputs of either 1.0 or 0.0 and recognizing when a post's offensiveness is not as discrete. To do so, we attempted to include following line: \"If the target or intent is unclear, or the content is borderline/ambiguous, output '0.5'.\" However, we noticed that this actually decreased model performance, as the models began to overuse the '0.5' label, and rarely did so correctly. We found middle ground between these two instances by imposing stricter requirements for a model to be allowed to use the maybe label. We also included a quick sanitization line, telling the model not to hallucinate information to fill in missing details or make unsupported assumptions. These changes aimed to encourage the model to better handle edge cases, reduce false certainty, and improve balanced use of all three labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ced6d5e-3891-467f-b5f7-41620b2ac1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_completion(model, message):\n",
    "    \"\"\"\n",
    "    Makes an API request to a LLM and returns the message.\n",
    "\n",
    "    Inputs:\n",
    "    model: A String representing the model we're using\n",
    "    message: A list of dictionaries, where each dictionary has two entries.\n",
    "    The first entry in each dictionary should have the key \"role\", and a value representing the role.\n",
    "    The second entry in each dictionary should have the key \"content\", and a value representing the content.\n",
    "\n",
    "    Returns:\n",
    "    A String representing the result of an API request to the model, parsed to just get the message back.\n",
    "\n",
    "    >>> model_choice = \"gpt-4o-mini\"\n",
    "    >>> message = [{\"role\": \"user\", \"content\": \"Hi there!\"}]\n",
    "    >>> isinstance(prompt(model_choice, message), str)\n",
    "    True\n",
    "    \"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "      model=model, # Picking model \n",
    "      messages=message # Supplying the message\n",
    "    )\n",
    "    response_json = completion.model_dump_json() \n",
    "    response_dict = json.loads(response_json)\n",
    "    return response_dict['choices'][0]['message']['content']\n",
    "    \n",
    "def llm_label(model, prompt, data):\n",
    "    labels = []\n",
    "    for post in data.column(\"post\"):\n",
    "        prompt[2][\"content\"] = post\n",
    "        labels.append(chat_completion(model, prompt))\n",
    "    return data.with_column(model, labels)\n",
    "\n",
    "\n",
    "\n",
    "theData = llm_label(\"gpt-4.1\", promptv3, theData)\n",
    "theData = llm_label(\"gpt-3.5-turbo\", promptv3, theData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5b6e949-b117-40d1-85c6-8eadc8d28e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for 4.1: recall: [ 0.77301927  0.82038835  0.24210526], precision: [ 0.82798165  0.74778761  0.20535714], macro_f1: 0.6013955539149337\n",
      "Stats for turbo: recall: [ 0.91220557  0.54126214  0.03157895], precision: [ 0.65740741  0.83208955  0.03571429], macro_f1: 0.4845091555173063\n",
      "The models disagreed 328 times out of 1000 labels.\n",
      "Here are some examples of disagreement:\n",
      "\n",
      "Gold:0.0 | gpt-4.1:0.0 | gpt-3.5-turbo:1.0 | post: tomorrow, 3 fucking PM EST yall are paying for my fallen cheek surgery and heal the petals from hanahaki !\n",
      "\n",
      "\n",
      "\n",
      "Gold:1.0 | gpt-4.1:0.0 | gpt-3.5-turbo:1.0 | post: Never met the bitch but I fucked her like I missed her\n",
      "\n",
      "\n",
      "\n",
      "Gold:0.0 | gpt-4.1:0.0 | gpt-3.5-turbo:0.5 | post: This is a problem that affects everyone, but we have seen far more harassment targeting women.\n",
      "\n",
      "\n",
      "\n",
      "Gold:0.5 | gpt-4.1:1.0 | gpt-3.5-turbo:0.0 | post: People think it's weird why I don't play with baby's But I was always told as a kid not to play with my food.\n",
      "\n",
      "\n",
      "\n",
      "Gold:1.0 | gpt-4.1:0.5 | gpt-3.5-turbo:1.0 | post: Which song would it be the victory theme for ethiopia It's raining,men\n",
      "\n",
      "\n",
      "\n",
      "Gold:0.0 | gpt-4.1:0.0 | gpt-3.5-turbo:1.0 | post: Encourage Twitter to purge more to speed up its destruction.\n",
      "\n",
      "\n",
      "\n",
      "Gold:0.0 | gpt-4.1:0.0 | gpt-3.5-turbo:1.0 | post: Official \"I'm not an Incel but have a question for /r/Incels\" thread\n",
      "Start another thread asking a single question and you will be permabanned (only applies to Non-incels.)\n",
      "\n",
      "\n",
      "\n",
      "Gold:0.5 | gpt-4.1:0.5 | gpt-3.5-turbo:1.0 | post: Got banned from r/ForeverAlone\n",
      "Guess those blue pilled cucks can't handle the truth.\n",
      "\n",
      "\n",
      "\n",
      "Gold:1.0 | gpt-4.1:0.0 | gpt-3.5-turbo:1.0 | post: Anybody else pissed Hillary is walking around today laughing after all the times she lied to the FBI?\n",
      "\n",
      "\n",
      "\n",
      "Gold:0.0 | gpt-4.1:0.0 | gpt-3.5-turbo:0.5 | post: Nothing trips me out more than feeling like a song's BPM is way off after hearing a faster/slower song beforehand #whyugottadomelikethis\n",
      "\n",
      "\n",
      "\n",
      "Gold:1.0 | gpt-4.1:1.0 | gpt-3.5-turbo:0.5 | post: I used to have a great rapport with my cousin, until I slept with one of his classmates. I don't think he's gonna stay mad and remember this for a long time tho as he's only 4 years old\n",
      "\n",
      "\n",
      "\n",
      "Gold:1.0 | gpt-4.1:1.0 | gpt-3.5-turbo:0.5 | post: What would be the title of Jumanji if it had an entire black cast Zoomanji\n",
      "\n",
      "\n",
      "\n",
      "Gold:0.0 | gpt-4.1:0.0 | gpt-3.5-turbo:1.0 | post: I really gotta quit school and get on welfare\n",
      "I cant stand being around others, its over\n",
      "\n",
      "\n",
      "\n",
      "Gold:1.0 | gpt-4.1:0.5 | gpt-3.5-turbo:0.0 | post: They are of Mediterranean type , it 's normal because of the temperature to have darker pigmentation , than fellow whites from western and northern Europe .\n",
      "\n",
      "\n",
      "\n",
      "Gold:0.5 | gpt-4.1:0.5 | gpt-3.5-turbo:1.0 | post: #resist what a great unifier for USA! Divided we fall, together we stand and prevail! Dems/libs want chaos and yell tostop others opinions\n",
      "\n",
      "\n",
      "\n",
      "Gold:1.0 | gpt-4.1:0.0 | gpt-3.5-turbo:1.0 | post: I won't say how many bitches I fucked but i might say how many 100s I touched &#128178;&#128178;&#128178;\n",
      "\n",
      "\n",
      "\n",
      "Gold:1.0 | gpt-4.1:0.0 | gpt-3.5-turbo:1.0 | post: .@jennofhardwire nice cropping of tweets, too. but the truth hurts.\n",
      "\n",
      "\n",
      "\n",
      "Gold:0.0 | gpt-4.1:0.0 | gpt-3.5-turbo:1.0 | post: THE FUCKING HARDY BOYZ AT WRESTLEMANIA AND WON WTF!!!!\n",
      "\n",
      "\n",
      "\n",
      "Gold:0.5 | gpt-4.1:0.5 | gpt-3.5-turbo:0.0 | post: Save your change or eat pork and beans one night instead of going out , and give the money to a White mother. photo crawling infant reaching out\n",
      "\n",
      "\n",
      "\n",
      "Gold:1.0 | gpt-4.1:1.0 | gpt-3.5-turbo:0.5 | post: #hashtag @137kHz #notsexist , but, a #womans 'ill be #ready in 5 minutes is the same length of time as a #mans 'ill be #home in 5 minutes'..\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Sample ground truth and predicted labels\n",
    "y_true = theData.column(\"offensiveYN\").astype(str)\n",
    "y_pred_41 = theData.column(\"gpt-4.1\")\n",
    "y_pred_turbo = theData.column(\"gpt-3.5-turbo\")\n",
    "\n",
    "labels = [\"1.0\", \"0.0\", \"0.5\"]\n",
    "\n",
    "# Compute per-class precision, recall, and F1 using sklearn\n",
    "precision_41 = precision_score(y_true, y_pred_41, labels=labels, average=None)\n",
    "precision_turbo = precision_score(y_true, y_pred_turbo, labels=labels, average=None)\n",
    "\n",
    "f1_per_class_41 = f1_score(y_true, y_pred_41, labels=labels, average=None, zero_division=0)\n",
    "f1_per_class_turbo = f1_score(y_true, y_pred_turbo, labels=labels, average=None, zero_division=0)\n",
    "\n",
    "macro_f1_41 = np.mean(f1_per_class_41)\n",
    "macro_f1_turbo = np.mean(f1_per_class_turbo)\n",
    "\n",
    "\n",
    "recall_41 = recall_score(y_true, y_pred_41, labels=labels, average=None)\n",
    "recall_turbo = recall_score(y_true, y_pred_turbo, labels=labels, average=None)\n",
    "print(f\"Stats for 4.1: recall: {recall_41}, precision: {precision_41}, macro_f1: {macro_f1_41}\")\n",
    "print(f\"Stats for turbo: recall: {recall_turbo}, precision: {precision_turbo}, macro_f1: {macro_f1_turbo}\")\n",
    " \n",
    "\n",
    "\n",
    "model_difference = theData.where(\"gpt-4.1\", are.not_equal_to, theData.column(\"gpt-3.5-turbo\")).select(\"offensiveYN\", \"post\", \"gpt-4.1\", \"gpt-3.5-turbo\")\n",
    "\n",
    "print(f\"The models disagreed {model_difference.num_rows} times out of {theData.num_rows} labels.\")\n",
    "print(\"Here are some examples of disagreement:\")\n",
    "i = 0\n",
    "for row in model_difference.rows:\n",
    "    print(f\"\\nGold:{row[0]} | gpt-4.1:{row[2]} | gpt-3.5-turbo:{row[3]} | post: {row[1]}\\n\\n\")\n",
    "    i += 1\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab4c09b-6f94-444e-81d3-14e0f2058a13",
   "metadata": {},
   "source": [
    "__Find all the instances where the models above labeled the response\n",
    "differently. Are there any patterns? Provide your own evaluation of which\n",
    "model's output you agree with most and explain why. Substantiate your\n",
    "evaluation with at least one example.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f90ddc0-c88e-486f-991a-c703ee5b8cda",
   "metadata": {},
   "source": [
    "As indicated by our analysis above, the models disagreed 328 times out 1000. There are a few patterns here:\n",
    "\n",
    "3.5-turbo seems particularly sensitive to profanity:\n",
    "\n",
    "Gold 0.0 | 4.1 0.0 | Turbo 1.0 → “THE FUCKING HARDY BOYZ AT WRESTLEMANIA…”\n",
    "\n",
    "Gold 0.0 | 4.1 0.0 | Turbo 1.0 → “tomorrow, 3 fucking PM EST…”\n",
    "\n",
    "Neither of these posts are offensive, yet turbo alone flags them as such. This is interesting as we explicitly prompted both models not to use profanity alone as an indicator for offensiveness. Nonetheless, this behavior is corroborated by our stats, with turbo having a high recall for \"yes\" labels but lower precision; this indicates that it over-labels the \"offensive\" category.\n",
    "\n",
    "Turbo also seems to struggle with more nuanced cases of bias:\n",
    "\n",
    "Gold 1.0 | 4.1 1.0 | Turbo 0.5 → “What would be the title of Jumanji if it had an entire black cast Zoomanji”\n",
    "\n",
    "Gold 1.0 | 4.1 1.0 | Turbo 0.5 → “The only black I love is my black coffee”\n",
    "\n",
    "Gold 1.0 | 4.1 1.0 | Turbo 0.5 → “#notsexist, but… a woman’s ‘5 minutes’…”\n",
    "\n",
    "4.1 is often able to correctly label these kinds of posts as offensive, while turbo doesn't seem to be able to pick up on the cues, and assigns \"maybe\".\n",
    "\n",
    "Both models seem to struggle in cases of uncertainty, often going different directions: \n",
    "\n",
    "Gold 0.5 | 4.1 0.0 | Turbo 1.0 — “SARCASMS the ability to insult idiots…”\n",
    "\n",
    "Gold:0.5 | gpt-4.1:0.0 | gpt-3.5-turbo:1.0 | post: If you can't except the fact i drink. I'll pop one open...\n",
    "\n",
    "Gold:0.5 | gpt-4.1:1.0 | gpt-3.5-turbo:0.0 | post: People think it's weird why I don't play with baby's But I was always told as a kid not to play with my food.\n",
    "\n",
    "This is the most expected pattern here; in cases in which even human annotators cannot decipher a post's intention, we likely cannot expect an LLM to perform accordingly.\n",
    "\n",
    "Overall, we agree with gpt-4.1's output more. It adhered to more strictly to the guideline that profanity does not automatically indicate offensiveness, and was more often able to pick up on nuanced cases of social bias. We think the following is a great example that demonstrates the edge 4.1 has over turbo, being able to read between the lines and correctly label a more complex example of social bias:\n",
    "\n",
    "“What would be the title of Jumanji if it had an entire black cast Zoomanji”\n",
    "Gold: 1.0 · 4.1: 1.0 __Good job 4.1!__· Turbo: 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf4b78-340e-4f48-954b-6c05fb72cb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
