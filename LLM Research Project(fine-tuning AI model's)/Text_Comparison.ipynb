{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install libraries\n",
        "!pip install scikit-learn python-Levenshtein nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5sloBWLwNBG",
        "outputId": "ec9eb540-870a-4fed-8e8e-58488f8ab26f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.25.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting Levenshtein==0.25.1 (from python-Levenshtein)\n",
            "  Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.8.0 (from Levenshtein==0.25.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Downloading python_Levenshtein-0.25.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.25.1 python-Levenshtein-0.25.1 rapidfuzz-3.9.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import Levenshtein\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "metadata": {
        "id": "X1wprdcfwPNR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the strings to compare\n",
        "string1 = \"This is a sample string.\"\n",
        "string2 = \"This is another example of a string.\""
      ],
      "metadata": {
        "id": "aDnELRiywUqH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosine Similarity"
      ],
      "metadata": {
        "id": "G49_lHT4wfRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine similarity measures the cosine of the angle between two non-zero vectors in a multi-dimensional space, indicating how similar the vectors are to each other. To evaluate its results, a cosine similarity score close to 1 indicates high similarity, 0 indicates orthogonality (no similarity), and -1 indicates complete dissimilarity. In text similarity, cosine similarity is relevant because it quantifies the similarity between two strings by comparing their vectorized representations."
      ],
      "metadata": {
        "id": "j_0-Re1uw68I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cosine Similarity\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform([string1, string2])\n",
        "cos_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
        "print(f\"Cosine Similarity: {cos_sim[0][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzkyi_lywSEB",
        "outputId": "ebec14a5-1542-43ad-8d4f-0b2432e66b6e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity: 0.4501755023269898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Jaccard Similarity"
      ],
      "metadata": {
        "id": "x7SFyfLawqOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jaccard similarity measures the size of the intersection divided by the size of the union of two sets, indicating the proportion of shared elements. To evaluate its results, a Jaccard similarity score of 1 means the sets are identical, 0 means they have no elements in common, and values in between indicate the degree of overlap. In text similarity, Jaccard similarity compares the commonality between two sets of words from text documents, highlighting how much of the content is shared."
      ],
      "metadata": {
        "id": "35U0V64Gw7Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Jaccard Similarity\n",
        "def jaccard_similarity(str1, str2):\n",
        "    set1 = set(str1.split())\n",
        "    set2 = set(str2.split())\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "    return len(intersection) / len(union)\n",
        "\n",
        "jaccard_sim = jaccard_similarity(string1, string2)\n",
        "print(f\"Jaccard Similarity: {jaccard_sim}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygl5GNOVwY5V",
        "outputId": "25b74fef-40de-4c80-b021-dfcf266fc1d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard Similarity: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Levenshtein Distance (Edit Distance)"
      ],
      "metadata": {
        "id": "NgaRmDXLwubv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Levenshtein distance measures the minimum number of single-character edits (insertions, deletions, or substitutions) needed to change one string into another. To evaluate its results, a lower Levenshtein distance indicates greater similarity between the two strings, with a distance of 0 meaning the strings are identical. In text similarity, Levenshtein distance is relevant because it quantifies the effort required to transform one text into another, capturing the direct differences between them.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7_5ZITJbw7vx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Levenshtein Distance (Edit Distance)\n",
        "lev_distance = Levenshtein.distance(string1, string2)\n",
        "print(f\"Levenshtein Distance: {lev_distance}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xzs19nBgwbu9",
        "outputId": "c6ba410f-db9a-4cdc-9324-d07148a3e55d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Levenshtein Distance: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BLEU Score"
      ],
      "metadata": {
        "id": "VCPc5r2rw3vP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLEU score (Bilingual Evaluation Understudy) measures the similarity between a candidate text and one or more reference texts based on the precision of n-grams. To evaluate its results, a BLEU score close to 1 indicates high similarity, meaning the candidate text closely matches the reference text(s), while a score closer to 0 indicates low similarity. In text similarity, BLEU score is relevant because it evaluates the quality of text generation or translation by comparing the overlap of n-grams, capturing both precision and the fluency of the candidate text."
      ],
      "metadata": {
        "id": "kw1qMfomw8IK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BLEU Score\n",
        "reference = string1.split()\n",
        "candidate = string2.split()\n",
        "bleu_score = sentence_bleu([reference], candidate)\n",
        "print(f\"BLEU Score: {bleu_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAAmHXFbwdN5",
        "outputId": "71a66949-c889-4f13-efdc-6df40d97f298"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 8.286571670851008e-155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    }
  ]
}